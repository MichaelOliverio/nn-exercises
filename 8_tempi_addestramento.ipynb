{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/dl00/blob/master/7%20-%20Addestramento%20in%20cloud%20e%20su%20GPUs/IMDB%20Classifier%20Benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "colab_type": "code",
        "id": "qZusEYlgUmnX",
        "outputId": "299667db-7bc5-4b2b-be17-0aa9c3a79712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non stai utilizzando la GPU\n",
            "--------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 8s 0us/step\n",
            "Dataset caricato in 22.3346 secondi\n",
            "--------------------------\n",
            "One hot enconding eseguito in 9.6301 secondi\n",
            "--------------------------\n",
            "Rete neurale creata in 1.0282 secondi\n",
            "--------------------------\n",
            "Modello compilato in 0.0401 secondi\n",
            "--------------------------\n",
            "Epoch 1/10\n",
            "49/49 [==============================] - 13s 153ms/step - loss: 22.4069 - accuracy: 0.5081\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 7s 145ms/step - loss: 1.2889 - accuracy: 0.5848\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 7s 146ms/step - loss: 0.9062 - accuracy: 0.6775\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 8s 161ms/step - loss: 0.7769 - accuracy: 0.7358\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 8s 164ms/step - loss: 0.7210 - accuracy: 0.7670\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 7s 152ms/step - loss: 0.6897 - accuracy: 0.7848\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 9s 179ms/step - loss: 0.6586 - accuracy: 0.8013\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 8s 159ms/step - loss: 0.6456 - accuracy: 0.8107\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 7s 148ms/step - loss: 0.6361 - accuracy: 0.8177\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 8s 168ms/step - loss: 0.6173 - accuracy: 0.8302\n",
            "--------------------------\n",
            "Addestramento completato in 85 secondi (10 epoche)\n",
            "\n",
            "\n",
            "Tempo di esecuzione totale: 118.4788 secondi\n"
          ]
        }
      ],
      "source": [
        "# Importiamo i moduli\n",
        "\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import History \n",
        "from keras import optimizers\n",
        "from time import time\n",
        "from keras.datasets import imdb \n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Definiamo le funzioni che ci serviranno\n",
        "\n",
        "def onehot_encoding(data, size):\n",
        "    onehot = np.zeros((len(data), size))\n",
        "    for i, d in enumerate(data):\n",
        "        onehot[i,d] = 1.\n",
        "    return onehot\n",
        "\n",
        "# Verifichiamo se stiamo utilizzando la GPU\n",
        "\n",
        "# Tensorflow 1.x\n",
        "# from keras import backend as K\n",
        "# gpus = K.tensorflow_backend._get_available_gpus()\n",
        "\n",
        "# Tensorflow 2.x\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "\n",
        "if(len(gpus)==0):\n",
        "    print(\"Non stai utilizzando la GPU\")\n",
        "else:\n",
        "    print(\"Stai utilizzando la GPU: %s\" % gpus)\n",
        "\n",
        "print(\"--------------------------\")\n",
        "# Carichiamo il dataset\n",
        "\n",
        "start_at = time()\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
        "\n",
        "print(\"Dataset caricato in %.4f secondi\" % (time()-start_at))\n",
        "print(\"--------------------------\")\n",
        "\n",
        "# Eseguiamo il one hot encoding\n",
        "\n",
        "start_at2 = time()\n",
        "\n",
        "X_train = onehot_encoding(X_train, 5000)\n",
        "X_test = onehot_encoding(X_test, 5000)\n",
        "\n",
        "print(\"One hot enconding eseguito in %.4f secondi\" % (time()-start_at2))\n",
        "print(\"--------------------------\")\n",
        "\n",
        "# Creiamo la rete\n",
        "\n",
        "start_at2 = time()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(5000,), kernel_regularizer=l2(0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128,activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8,activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(\"Rete neurale creata in %.4f secondi\" % (time()-start_at2))\n",
        "print(\"--------------------------\")\n",
        "\n",
        "\n",
        "# Compiliamo il modello\n",
        "\n",
        "start_at2 = time()\n",
        "\n",
        "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Modello compilato in %.4f secondi\" % (time()-start_at2))\n",
        "print(\"--------------------------\")\n",
        "\n",
        "# Eseguiamo l'addestramento\n",
        "\n",
        "start_at2 = time()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=512)\n",
        "\n",
        "print(\"--------------------------\")\n",
        "print(\"Addestramento completato in %.f secondi (%d epoche)\" % ((time()-start_at2), epochs))\n",
        "print(\"\\n\")\n",
        "print(\"Tempo di esecuzione totale: %.4f secondi\" % (time()-start_at))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QUBY2lJzUmnb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Copia di IMDB Classifier Benchmark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
